{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiener filters\n",
    "\n",
    "This notebook implements the most basic Wiener filter, which is intended to filter observed data $d_i^\\text{obs}$ for $i=0, ..., N-1$ using the $n$-point discrete convolution\n",
    "\n",
    "\\begin{equation}\n",
    "d_i = \\sum_{j=0}^{n-1} d_{i-j}^\\text{obs} p_j\\,.\n",
    "\\end{equation}\n",
    "\n",
    "Wiener filters are designed to minimise the difference between $d_i$ and some desired signal $x_i$. Typically, $x_i$ an unknown noise-free version of $d_i^\\text{obs}$.\n",
    "\n",
    "The task of finding the $n$ filter coefficients $p_j$ can be formulated as an inverse problem. Assuming that the observational errors are Gaussian with covariance matrix $\\mathbf{C}$, the maximum-likelihood set of coefficients minimises the least-squares misfit functional\n",
    "\n",
    "\\begin{equation}\n",
    "\\chi(\\mathbf{p}) = \\frac{1}{2} \\sum_{i,j=0}^{N-1} (d_i - x_i) C_{ij}^{-1} (d_j - x_j)\\,.\n",
    "\\end{equation}\n",
    "\n",
    "Inserting the forward modelling equation and forcing the derivative of $\\chi$ to zero, yields the normal equations\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i,j=0}^{N-1} x_i C_{ij}^{-1} d_{j-q}^\\text{obs} = \\sum_{k=0}^{n-1} \\left( \\sum_{i,j=0}^{N-1} d_{i-k}^\\text{obs} C_{ij}^{-1} d_{j-q}^\\text{obs} \\right)\\,p_k\\,.\n",
    "\\end{equation}\n",
    "\n",
    "This can be written in vector-matrix form,\n",
    "\n",
    "\\begin{equation}\n",
    "b_q = \\sum_{k=0}^{n-1} A_{qk} p_k\\,,\n",
    "\\end{equation}\n",
    "\n",
    "with the cross-correlation vector between observed and ideal data,\n",
    "\n",
    "\\begin{equation}\n",
    "b_q = \\sum_{i,j=0}^{N-1} x_i C_{ij}^{-1} d_{j-q}^\\text{obs}\\,,\n",
    "\\end{equation}\n",
    "\n",
    "and the auto-correlation matrix between the observed data,\n",
    "\n",
    "\\begin{equation}\n",
    "A_{qk}=\\sum_{i,j=0}^{N-1} d_{i-k}^\\text{obs} C_{ij}^{-1} d_{j-q}^\\text{obs}\\,.\n",
    "\\end{equation}\n",
    "\n",
    "The crux of the problem is of course that the ideal data are unknown. Yet, we may obtain an estimate of $b_q$ under the assumption that the noise time series $n_i$ is additive to the ideal data in the sense of\n",
    "\n",
    "\\begin{equation}\n",
    "d_i^\\text{obs} = x_i + n_i\\,.\n",
    "\\end{equation}\n",
    "\n",
    "Furthermore, when noise and data are uncorrelated, we may change the expression for $b_q$ to\n",
    "\n",
    "\\begin{equation}\n",
    "b_q = \\sum_{i,j=0}^{N-1} x_i C_{ij}^{-1} x_{j-q}\\,.\n",
    "\\end{equation}\n",
    "\n",
    "It follows that the filter may be constructed just from the cross-correlation properties of the ideal data, without actually knowing them explicitly.\n",
    "\n",
    "The data needed for this notebook can be downloaded with this Polybox link: https://polybox.ethz.ch/index.php/s/a3EDhinFdATu4qt ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Packages and setup\n",
    "\n",
    "Import the necessary Python packages and add a few lines to embellish figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "import numpy as np\n",
    "import time as time\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.signal.filter import bandpass\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times\"\n",
    "plt.rcParams.update({'font.size': 50})\n",
    "plt.rcParams['xtick.major.pad']='12'\n",
    "plt.rcParams['ytick.major.pad']='12'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. General input\n",
    "\n",
    "Basic input, including the file to be read and the average spacing between channels."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# AVALANCHE DATA ========================================\n",
    "\n",
    "# Input file.\n",
    "input_file='/Users/andreas/Desktop/PEF/av3009_raw.npy'\n",
    "# Scale for plotting.\n",
    "scale=7\n",
    "# Receiver spacing.\n",
    "dx=2.0\n",
    "# Time increment.\n",
    "dt=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIMSVÃ–TN DATA ========================================\n",
    "\n",
    "# Input file.\n",
    "input_file='/Users/andreas/Desktop/PEF/2021-05-26T00_02_14.998000Z.npy'\n",
    "# Scale for plotting.\n",
    "scale=2\n",
    "# Receiver spacing.\n",
    "dx=8.0\n",
    "# Time increment.\n",
    "dt=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data reading and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Read and plot complete data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading in all the data and plotting them for an initial inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cct=np.load(input_file)\n",
    "\n",
    "nt=cct.shape[1]\n",
    "nx=cct.shape[0]-1\n",
    "\n",
    "t=np.linspace(0.0,nt*dt,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting all data might take a long time. So, one may want to deactivate this part of the notebook."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30,40))\n",
    "\n",
    "for i,j in enumerate(cct):\n",
    "    \n",
    "    if i % 100 == 0: print(f\"At {i} of {np.shape(cct)[0]}\")\n",
    "    \n",
    "    data = j/200.0 #np.mean(np.abs(j))\n",
    "    #data /= np.max(np.abs(data))        \n",
    "    dist_var = (i-1)*dx\n",
    "    \n",
    "    plt.plot(t,(scale*data)+dist_var,'k-', alpha = 0.4)\n",
    "    plt.fill_between(t,(scale*data)+dist_var,y2=np.ones(np.shape(t))*dist_var,where=(data+dist_var>=dist_var), interpolate=True,fc='k',alpha=0.8)\n",
    "\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('distance [m]')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filtering and downsampling\n",
    "\n",
    "For some applications, we may want to reduce the data volume through the application of a bandpass and by down-sampling. This is not strictly needed, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum and maximum frequencies [Hz].\n",
    "freqmin=0.1\n",
    "freqmax=49.0\n",
    "# Downsampling factor.\n",
    "downsample=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency-domain filtering.\n",
    "cct_filt=np.zeros(np.shape(cct))\n",
    "for i in range(cct.shape[0]-1): cct_filt[i,:]=bandpass(cct[i,:],freqmin=freqmin,freqmax=freqmax,df=1.0/dt,corners=4,zerophase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling.\n",
    "cct_filt_down=cct_filt[:,0:nt:downsample]\n",
    "\n",
    "nx=cct_filt_down.shape[0]-1\n",
    "nt=cct_filt_down.shape[1]\n",
    "dt=downsample*dt\n",
    "\n",
    "t=np.linspace(0.0,nt*dt,nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the pre-processed data. Also this may take a long time."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30,40))\n",
    "\n",
    "for i in range(nx):\n",
    "    \n",
    "    if i % 100 == 0: print(f\"At {i} of {nx}\")\n",
    "    \n",
    "    data = cct_filt_down[i,:]/np.mean(np.abs(cct_filt_down[i,:]))       \n",
    "    dist_var = (i-1)*dx\n",
    "    \n",
    "    plt.plot(t,(scale*data)+dist_var,'k-', alpha = 0.4)\n",
    "    plt.fill_between(t,(scale*data)+dist_var,y2=np.ones(np.shape(t))*dist_var,where=(data+dist_var>=dist_var), interpolate=True,fc='k',alpha=0.8)\n",
    "\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('distance [m]')\n",
    "plt.grid()\n",
    "plt.savefig('OUTPUT/filtered.png',dpi=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Pick a specific trace\n",
    "\n",
    "As data, we first pick one of the available traces. We will use this trace to estimate the noise covariance matrix $\\mathbf{C}$, as well as the vector $\\mathbf{b}$ that we need for the Wiener filter coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the trace.\n",
    "i_trace=360\n",
    "# Pick trace.\n",
    "d=cct_filt_down[i_trace,:]\n",
    "\n",
    "# Plot individual trace.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(d,'k')\n",
    "plt.grid()\n",
    "plt.xlabel('sample index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Noise covariance matrix\n",
    "\n",
    "We first need an estimate of the data covariance matrix $\\mathbf{C}$. For this, we first need to determine the size of the training dataset $N$. We then take a window of this length and slide it across the noise part of the signal, prior to the first wave arrivals. From this, we get average cross-correlations between pairs of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points in the dataset. This is needed to determine the size of the data covariance matrix.\n",
    "Nd=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation vector.\n",
    "corr=np.zeros(Nd)\n",
    "\n",
    "# Minimum and maximum indices from the noise time series.\n",
    "imin=100\n",
    "imax=3900\n",
    "\n",
    "# Compute mean and remove from data.\n",
    "mean=np.mean(d[imin:imax])\n",
    "d-=mean\n",
    "\n",
    "# Compute correlation vector.\n",
    "for j in np.arange(imin,imax):\n",
    "    for i in range(Nd):\n",
    "        corr[i]+=d[j]*d[j+i]\n",
    "\n",
    "corr/=np.float(imax-imin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(corr,'k')\n",
    "plt.grid()\n",
    "plt.title('average noise cross-correlation',pad=30)\n",
    "plt.xlabel('sample index')\n",
    "plt.xlim([0,Nd-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally build $\\mathbf{C}$ from the average cross-correlation by putting shifted copies of it into the rows of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=np.zeros([Nd,Nd])\n",
    "for i in range(Nd): C[i,:]=np.roll(corr,i)\n",
    "Cinv=np.linalg.inv(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Filtering\n",
    "\n",
    "## 4.1. Computing filter coefficients\n",
    "\n",
    "We start by picking out a part of the time series that we are interested in. Based on this, we build the vector $\\mathbf{b}$ and the matrix $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting index of the time series of interest.\n",
    "i0=3900\n",
    "\n",
    "# Plot the section of the time series of interest.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(np.arange(i0-50,i0+Nd+50),d[i0-50:i0+Nd+50],'--k')\n",
    "plt.plot(np.arange(i0,i0+Nd),d[i0:i0+Nd],'k',LineWidth=4)\n",
    "plt.grid()\n",
    "plt.xlim([i0-50,i0+Nd+50])\n",
    "plt.title('data',pad=20)\n",
    "plt.xlabel('sample index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we assemble $\\mathbf{b}$ and $\\mathbf{A}$. To make this more efficient, we use the fact that the matrix $X_{i,q}=\\sum_{j=0}^{N} C_{ij}^{-1} d_{j-q}^\\text{obs}$ appears in both $\\mathbf{b}$ and $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Wiener filter coefficients.\n",
    "n=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that builds the matrix $\\mathbf{A}$ for a specific input datum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix(d,plot=False):\n",
    "\n",
    "    # Build the auxiliary matrix X.\n",
    "    X=np.zeros([Nd,n])\n",
    "    for q in range(n): X[:,q]=np.dot(Cinv,d[(i0-q):(i0-q+Nd)])\n",
    "\n",
    "    # Build matrix A.\n",
    "    A=np.zeros([n,n])\n",
    "    for k in range(n): A[:,k]=np.dot(d[(i0-k):(i0-k+Nd)],X)\n",
    "\n",
    "    # Plot matrix.\n",
    "    if plot:\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.pcolor(A)\n",
    "        plt.title('auto-correlation matrix A',pad=30)\n",
    "        plt.show()\n",
    "\n",
    "    # Return.\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the vector $\\mathbf{b}$ using a rough estimate of the perfect data. We obtain this estimate by picking out a part of the time series that we think is dominated by actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out a part of the trace.\n",
    "d0=d.copy()\n",
    "d0[:4129]=0.0\n",
    "d0[4140:]=0.0\n",
    "\n",
    "# Smooth a bit.\n",
    "for s in range(3): d0[1:nt-1]=(2.0*d0[1:nt-1]+d0[0:nt-2]+d0[2:nt])/4.0\n",
    "\n",
    "# Plot the result.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(np.arange(i0,i0+Nd),d0[i0:i0+Nd],'k',LineWidth=4)\n",
    "plt.xlabel('sample index',labelpad=15)\n",
    "plt.xlim(4050,4200)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "filename='OUTPUT/ideal_waveform.png'\n",
    "plt.savefig(filename,dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Compute b.\n",
    "X=np.zeros([Nd,n])\n",
    "for q in range(n): X[:,q]=np.dot(Cinv,d[(i0-q):(i0-q+Nd)])\n",
    "b=np.dot(d0[i0:(i0+Nd)],X)\n",
    "\n",
    "# Plot b.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(b,'k')\n",
    "plt.plot(b,'ro')\n",
    "plt.grid()\n",
    "plt.title('cross-correlation vector b',pad=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the matrix A.\n",
    "A=matrix(d,plot=True)\n",
    "\n",
    "# Solve linear system.\n",
    "p=np.dot(np.linalg.inv(A),b)\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(p,'k')\n",
    "plt.plot(p,'ro')\n",
    "plt.grid()\n",
    "plt.title('Wiener filter coefficients',pad=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Application of the filter\n",
    "\n",
    "It remains to apply the convolutional Wiener filter and to compare with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction.\n",
    "d_pred=np.zeros(Nd)\n",
    "\n",
    "for j in range(Nd):\n",
    "    for i in range(n):\n",
    "        d_pred[j]+=d[i0+j-i]*p[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the comparison of observed and predicted data.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(np.arange(i0-50,i0+Nd+50),d[i0-50:i0+Nd+50],'--k')\n",
    "plt.plot(np.arange(i0,i0+Nd),d[i0:i0+Nd],'k',LineWidth=4)\n",
    "plt.plot(np.arange(i0,i0+Nd),d_pred,'r',LineWidth=3)\n",
    "plt.grid()\n",
    "plt.xlim([i0-50,i0+Nd+50])\n",
    "plt.title('observation/prediction comparison',pad=30)\n",
    "plt.xlabel('sample index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Filtering a different time series\n",
    "\n",
    "Now that we have seen how this works, we look at a different time series from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the trace.\n",
    "i_trace_new=363\n",
    "# Pick trace.\n",
    "d_new=cct_filt_down[i_trace_new,:]\n",
    "\n",
    "# Plot individual trace.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(d_new,'k')\n",
    "plt.grid()\n",
    "plt.xlabel('sample index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to solve for the new set of filter coefficients. Quite often, the filter coefficients for different time series look pretty similar, and so one may actually also reuse them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for the Wiener filter coefficients.\n",
    "# Compute the matrix A.\n",
    "A=matrix(d_new,plot=True)\n",
    "\n",
    "# Solve linear system.\n",
    "p=np.dot(np.linalg.inv(A),b)\n",
    "\n",
    "# Compute the prediction.\n",
    "d_pred=np.zeros(Nd)\n",
    "\n",
    "for j in range(Nd):\n",
    "    for i in range(n):\n",
    "        d_pred[j]+=d_new[i0+j-i]*p[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we compare the original and the filtered time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the comparison of observed and predicted data.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(np.arange(i0-50,i0+Nd+50),d_new[i0-50:i0+Nd+50],'--k')\n",
    "plt.plot(np.arange(i0,i0+Nd),d_new[i0:i0+Nd],'k',LineWidth=4)\n",
    "plt.plot(np.arange(i0,i0+Nd),d_pred,'r',LineWidth=3)\n",
    "plt.grid()\n",
    "plt.xlim([i0-50,i0+Nd+50])\n",
    "plt.title('observation/prediction comparison',pad=30)\n",
    "plt.xlabel('sample index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Repeating this for a part of the record section\n",
    "\n",
    "Having gained some confidence, we now do this for a bigger part of the record section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Plot the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimun and maximum trace indices.\n",
    "ix_min=0\n",
    "ix_max=1400\n",
    "\n",
    "# Trace normalisation for plotting.\n",
    "normalisation=200.0\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "\n",
    "for i in np.arange(ix_min,ix_max):\n",
    "        \n",
    "    data = cct_filt_down[i,i0:i0+Nd]/normalisation     \n",
    "    dist_var = (i-1)*dx\n",
    "    \n",
    "    plt.plot(t[i0:i0+Nd],(scale*data)+dist_var,'k-', alpha = 0.4)\n",
    "    plt.fill_between(t[i0:i0+Nd],(scale*data)+dist_var,y2=np.ones(np.shape(t[i0:i0+Nd]))*dist_var,where=(data+dist_var>=dist_var), interpolate=True,fc='k',alpha=0.8)\n",
    "\n",
    "plt.xlabel('time [s]',labelpad=20)\n",
    "plt.ylabel('distance [m]',labelpad=20)\n",
    "plt.title('raw data',pad=30)\n",
    "plt.xlim(40.0,43.0)\n",
    "plt.ylim(1000.0,5000.0)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "filename='OUTPUT/raw_data.png'\n",
    "plt.savefig(filename,dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Compute Wiener filter coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the time series we compute the Wiener filter coefficients and apply the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot matrix and coefficients.\n",
    "plot=False\n",
    "\n",
    "# Compute the prediction.\n",
    "d_filt=np.zeros([ix_max-ix_min,Nd])\n",
    "\n",
    "# Loop through the traces.\n",
    "for k in range(ix_max-ix_min):\n",
    "    \n",
    "    # Pick out the current trace.\n",
    "    d_new=cct_filt_down[ix_min+k,:]\n",
    "    \n",
    "    # Solve for the Wiener filter coefficients.\n",
    "    A=matrix(d_new,plot)\n",
    "    p=np.dot(np.linalg.inv(A),b)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(30,10))\n",
    "        plt.plot(p,'k')\n",
    "        plt.plot(p,'ro')\n",
    "        plt.grid()\n",
    "        plt.title('Wiener filter coefficients',pad=30)\n",
    "        plt.show()\n",
    "    \n",
    "    # Apply the filter.\n",
    "    for j in range(Nd):\n",
    "        for i in range(n):\n",
    "            d_filt[k,j]+=d_new[i0+j-i]*p[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Plot the filtered record section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "normalisation=25\n",
    "\n",
    "for i in range(ix_max-ix_min):\n",
    "        \n",
    "    data = d_filt[i,:]/normalisation  \n",
    "    dist_var = (i+ix_min-1)*dx\n",
    "    \n",
    "    plt.plot(t[i0:i0+Nd],(scale*data)+dist_var,'k-', alpha = 0.4)\n",
    "    plt.fill_between(t[i0:i0+Nd],(scale*data)+dist_var,y2=np.ones(np.shape(t[i0:i0+Nd]))*dist_var,where=(data+dist_var>=dist_var), interpolate=True,fc='k',alpha=0.8)\n",
    "\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('distance [m]')\n",
    "plt.title('filtered data')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Application in orthogonal direction for a single time sample index\n",
    "\n",
    "Apply the filter simply in the other direction, i.e., with distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Wiener filter coefficients.\n",
    "n=5\n",
    "# Number of traces that are included.\n",
    "Nt=ix_max-ix_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Pick out the traces for the selected time sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the time sample.\n",
    "i_sample=245\n",
    "# Pick time sample, padded by zeroes.\n",
    "d=np.zeros(Nt+2*n)\n",
    "d[n:n+Nt]=d_filt[:,i_sample]\n",
    "\n",
    "# Plot individual trace.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(d,'k')\n",
    "plt.grid()\n",
    "plt.xlabel('trace index')\n",
    "#plt.xlim([350,400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Estimate noise covariance matrix\n",
    "\n",
    "We try to estimate the noise covariance matrix from a few traces before the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation vector.\n",
    "corr=np.zeros(Nt)\n",
    "\n",
    "# Minimum and maximum indices of the samples used to estimate the noise covariance.\n",
    "# This needs to make sure than only those time samples are included that are actual noise.\n",
    "imin=0\n",
    "imax=20\n",
    "\n",
    "# Number of different reference indices with respect to which the correlation vector is computed.\n",
    "Nref=50\n",
    "\n",
    "# Loop over time samples over which we average.\n",
    "for j in np.arange(imin,imax-1):\n",
    "    # Loop over correlation lags.\n",
    "    for i in range(Nt):\n",
    "        # To obtain a more reasonable result, also loop over reference indices.\n",
    "        for k in range(Nref):\n",
    "            corr[i]+=np.roll(d_filt[:,j],k)[0]*np.roll(d_filt[:,j],k)[i]\n",
    "\n",
    "corr/=np.float(Nref*(imax-imin))\n",
    "\n",
    "# Smooth a bit.\n",
    "for s in range(2): corr[1:Nt-1]=(2.0*corr[1:Nt-1]+corr[0:Nt-2]+corr[2:Nt])/4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(corr,'k')\n",
    "plt.grid()\n",
    "plt.title('average noise cross-correlation',pad=30)\n",
    "plt.xlabel('trace index')\n",
    "plt.xlim([-1,Nt])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=np.zeros([Nt,Nt])\n",
    "for i in range(Nt): C[i,:]=np.roll(corr,i)\n",
    "Cinv=np.linalg.inv(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Compute cross-correlation vector\n",
    "\n",
    "For this, we again pick out a part of the trace that we think is dominated by actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out a part of the trace.\n",
    "d0=d.copy()\n",
    "d0[:362]=0.0\n",
    "d0[380:]=0.0\n",
    "\n",
    "# Smooth a bit.\n",
    "for s in range(2): d0[1:Nt+2*n-1]=(2.0*d0[1:Nt+2*n-1]+d0[0:Nt+2*n-2]+d0[2:Nt+2*n])/4.0\n",
    "\n",
    "# Plot the result.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(np.arange(0,0+Nt),d0[0:0+Nt],'k',LineWidth=4)\n",
    "plt.xlim(350,450)\n",
    "plt.show()\n",
    "\n",
    "# Compute b.\n",
    "X=np.zeros([Nt,n])\n",
    "for q in range(n): X[:,q]=np.dot(Cinv,d[(n-q):(n-q+Nt)])\n",
    "b=np.dot(d0[n:(n+Nt)],X)\n",
    "\n",
    "# Plot b.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(b,'k')\n",
    "plt.plot(b,'ro')\n",
    "plt.grid()\n",
    "plt.title('cross-correlation vector b',pad=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Compute auto-correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we again define a function that computes the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2(d,plot=False):\n",
    "\n",
    "    # Build the auxiliary matrix X.\n",
    "    X=np.zeros([Nt,n])\n",
    "    for q in range(n): X[:,q]=np.dot(Cinv,d[(n-q):(n-q+Nt)])\n",
    "\n",
    "    # Build matrix A.\n",
    "    A=np.zeros([n,n])\n",
    "    for k in range(n): A[:,k]=np.dot(d[(n-k):(n-k+Nt)],X)\n",
    "\n",
    "    # Plot matrix.\n",
    "    if plot:\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.pcolor(A)\n",
    "        plt.title('auto-correlation matrix A',pad=30)\n",
    "        plt.show()\n",
    "\n",
    "    # Return.\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can then compute and plot $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the matrix A.\n",
    "A=matrix2(d,plot=True)\n",
    "\n",
    "# Solve linear system.\n",
    "p=np.dot(np.linalg.inv(A),b)\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(p,'k')\n",
    "plt.plot(p,'ro')\n",
    "plt.grid()\n",
    "plt.title('Wiener filter coefficients',pad=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. Apply the filter and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction.\n",
    "d_pred=np.zeros(Nt)\n",
    "\n",
    "for j in range(Nt):\n",
    "    for i in range(n):\n",
    "        d_pred[j]+=d[n+j-i]*p[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the comparison of observed and predicted data.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(np.arange(0,Nt),d[n:n+Nt],'k',LineWidth=4)\n",
    "plt.plot(np.arange(0,Nt),d_pred,'r',LineWidth=3)\n",
    "plt.grid()\n",
    "plt.title('observation/prediction comparison',pad=30)\n",
    "plt.xlabel('sample index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Application in orthogonal direction for all time indices\n",
    "\n",
    "On the basis of the previous developments, we now apply the filter to all time samples. For simplicity, we keep $\\mathbf{b}$ constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction.\n",
    "d_filt2=np.zeros(np.shape(d_filt))\n",
    "\n",
    "# Loop over time sample indices.\n",
    "for i_sample in range(Nd):\n",
    "    \n",
    "    # Pick time sample, padded by zeroes.\n",
    "    d=np.zeros(Nt+2*n)\n",
    "    d[n:n+Nt]=d_filt[:,i_sample]\n",
    "\n",
    "    # Compute the matrix A.\n",
    "    A=matrix2(d)\n",
    "\n",
    "    # Solve linear system.\n",
    "    p=np.dot(np.linalg.inv(A),b)\n",
    "    \n",
    "    for j in range(Nt):\n",
    "        for i in range(n):\n",
    "            d_filt2[j,i_sample]+=d[n+j-i]*p[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "\n",
    "normalisation=0.7\n",
    "\n",
    "for i in range(ix_max-ix_min):\n",
    "        \n",
    "    data = d_filt2[i,:]/normalisation       \n",
    "    dist_var = (i+ix_min-1)*dx\n",
    "    \n",
    "    plt.plot(t[i0:i0+Nd],(scale*data)+dist_var,'k-', alpha = 0.4)\n",
    "    plt.fill_between(t[i0:i0+Nd],(scale*data)+dist_var,y2=np.ones(np.shape(t[i0:i0+Nd]))*dist_var,where=(data+dist_var>=dist_var), interpolate=True,fc='k',alpha=0.8)\n",
    "\n",
    "plt.xlabel('time [s]',labelpad=20)\n",
    "plt.ylabel('distance [m]',labelpad=20)\n",
    "plt.xlim(40.0,43.0)\n",
    "plt.ylim(1000.0,5000.0)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "filename='OUTPUT/filtered_data.png'\n",
    "plt.savefig(filename,dpi=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
